<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RAG on PoolBee的博客</title>
    <link>http://localhost:1313/tags/rag/</link>
    <description>Recent content in RAG on PoolBee的博客</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 13 Aug 2024 19:14:39 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大模型RAG基础知识</title>
      <link>http://localhost:1313/post/rag/</link>
      <pubDate>Tue, 13 Aug 2024 19:14:39 +0000</pubDate>
      <guid>http://localhost:1313/post/rag/</guid>
      <description>什么是RAG 知识局限性：大模型的知识来源于训练数据，而这些数据主要来自于互联网上已经公开的资源，对于一些实时性的或者非公开的，由于大模型没有获取到相关数据，这部分知识也就无法被掌握。&#xA;数据安全性：为了使得大模型能够具备相应的知识，就需要将数据纳入到训练集进行训练。然而，对于企业来说，数据的安全性至关重要，任何形式的数据泄露都可能对企业构成致命的威胁。&#xA;大模型幻觉：由于大模型是基于概率统计进行构建的，其输出本质上是一系列数值运算。因此，有时会出现模型“一本正经地胡说八道”的情况，尤其是在大模型不具备的知识或不擅长的场景中。&#xA;检索增强生成（Retrieval Augmented Generation, RAG），引入外部知识，使大模型能够生成准确且符合上下文的答案，同时能够减少模型幻觉的出现。&#xA;1概览：一个完整的RAG链路 从上图可以看到，大模型接收到用户query后，RAG会先进行检索。&#xA;检索(Retrieval)：检索 Chunks 和 query 一并输入到大模型，进而回答用户的问题。&#xA;Chunks：query和离线文档经过parser和splitter（orc）向量化（或称索引）——&amp;gt;到Datebase然后和query一起进行Retrieval——&amp;gt;检索到相关的Chunks&#xA;第二次Retrieval——&amp;gt;输入query和相关的Chunks然后得到reanked的Chunks输入到LLM后得到Answer&#xA;query：在第一次Retrieval和第二次Retrieval的时候输入&#xA;为了完成检索，需要离线将文档（ppt、word、pdf等）经过解析、切割甚至OCR转写，然后进行向量化存入数据库中。 接下来，我们将分别介绍离线计算和在线计算流程。&#xA;1.1离线计算流程 文件（pdf、word、ppt等，这些 文档documents）——解析parser——&amp;gt;切割为较短的Chunk——清洗和去重。&#xA;知识库中知识的数量和质量决定了RAG的效果，因此这是非常关键且必不可少的环节。 向量化（Vectorization）：Chunk转化为向量或者 索引（Indexing）。 具体是构建**向量模型（Embedding Model）**作用是将一段 Chunk 转成 向量（Embedding）&#xA;一个好的向量模型，会使得具有相同语义的文本的向量表示在语义空间中的距离会比较近，而语义不同的文本在语义空间中的距离会比较远。 由于知识库中的所有 Chunk 都需要进行 向量化，这会使得计算量非常大，因此这一过程通常是离线完成的。&#xA;随着新知识的不断存储，向量的数量也会不断增加。这就需要将这些向量存储到 数据库 （DataBase）中进行管理，例如 Milvus 中。&#xA;离线计算总结： 离线计算就是在文档在parse&amp;amp;splitter后将得到的Chunk进行向量化（Vectorization）或称 索引（Indexing），随着向量的数量不断增加会将向量存储到Milvus等数据库中。&#xA;因为Chunk进行向量化的时候会使得计算量非常大，通常是离线进行的。&#xA;1.2在线计算 **检索（Retrieval）：**RAG系统使用时候，给定一条用户 查询（Query），从知识库中找到所需的知识的操作。 具体过程：Query会经过向量模型（Embedding Model）【是的也就是向量化】得到相应向量，然后与数据库中所有的Chunk的向量计算相似度*，得到最相近的一系列Chunk。&#xA;但 数据库 非常大的时候，向量相似度的计算过程需要一定的时间。&#xA;这时可以在索引之前那召回（Recall）：从 数据库 中快速获得大量大概率相关的 Chunk，**然后只有这些 Chunk 会参与计算向量相似度。**使得计算的复杂度就从整个知识库降到了非常低。&#xA;召回（Recall）： 召回（Recall）：通常采用简单的基于字符串的匹配算法，常用的算法有 TF-IDF，BM25 。【由于这些算法不需要任何模型，速度会非常快】&#xA;也有还是致力于实现更快的 向量检索的 ，例如 faiss，annoy **总结：**在查询（Query）前增加了召回（recall），即从数据库中快速获得大量大概率相关的Chunk，用这些大概率相关的Chunk进行计算向量相似度。达到降低计算复杂度的效果。&#xA;思维导图：向量化——query所有向量进行计算向量相似度，得到Chunk&#xA;而是在此之前增加recall进行大概率相关的Chunk计算向量相似度。</description>
    </item>
  </channel>
</rss>
